{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_template_matching",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/machine-perception-robotics-group/ImageProcessingGoogleColabNotebooks/blob/master/06_template_matching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "844HprfC2ezF",
        "colab_type": "text"
      },
      "source": [
        "# 06. テンプレートマッチング\n",
        "講義で説明する画像処理の方法について，google colaboratoryを利用して演習する．\n",
        "google colaboratoryは，クラウドで実行する Jupyter ノートブック環境である.\n",
        "google coraboratoryについては，[ここ](https://www.tdi.co.jp/miso/google-colaboratory-gpu)や[ここ](https://www.codexa.net/how-to-use-google-colaboratory/)を参考にすること．\n",
        "\n",
        "下記のプログラムを実行すると，様々な類似尺度を用いたテンプレートマッチングや高速化のための粗密探索を実行する．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Bbaet2C4U7F",
        "colab_type": "text"
      },
      "source": [
        "## 準備\n",
        "プログラムの動作に必要なデータをダウンロードし，zipファイルを解凍する．\n",
        "`!`で始まるコマンドはPythonではなく，Linux（Ubuntu）のコマンドを実行している．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NYtuZtndzQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q http://www.mprg.cs.chubu.ac.jp/Tutorial/ML_Lecture/tutorial_ip_2020/image1.zip\n",
        "!unzip -q image1.zip\n",
        "!ls\n",
        "!ls ./image1/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkwrQ8dwa2sZ",
        "colab_type": "text"
      },
      "source": [
        "## 画像の読み込みと表示\n",
        "必要なパッケージをインポートし，画像を表示する．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YFl5XkzmZCg9",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "img1 = cv2.imread('./image1/woman-t.jpg', 0)\n",
        "img2 = cv2.imread('./image1/woman-g.jpg', 0)\n",
        "\n",
        "plt.imshow(img1, cmap=\"gray\")\n",
        "plt.title(\"template\")\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(img2, cmap=\"gray\")\n",
        "plt.title(\"original\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNRF8z1MGlOT",
        "colab_type": "text"
      },
      "source": [
        "## 類似尺度\n",
        "\n",
        "テンプレートマッチングでは，テンプレートと入力画像の画素比較によって類似度を算出する．類似度の高い位置を算出することで入力画像中のテンプレート画像位置を探索できる．\n",
        "\n",
        "テンプレートマッチングで使用する類似尺度は様々なものがある．\n",
        "ここでは，以下の類似尺度を使用してテンプレートマッチングを行う．\n",
        "\n",
        "* Sum of Squared Difference (SSD)\n",
        "* Sum of Absolute Difference (SAD)\n",
        "* 正規化相互相関（Normalized Cross-Correlation）\n",
        "* ゼロ平均相互相関係数（Zero-means Normalized Cross-Correlation）\n",
        "\n",
        "まず，はじめに類似尺度を計算するための関数を定義する．\n",
        "ここでは，テンプレートと類似度を計算したい画像の局所領域を入力した際に，その類似度を計算して返すような関数を定義する．\n",
        "\n",
        "全ての関数において，入力された画像は`flatten`関数によって2次元配列から1次元配列へと並び替えられる（`ravel`と同様の効果）．\n",
        "\n",
        "その後，各尺度の定義に合わせて類似度を計算する．\n",
        "ここでは，Numpy配列の演算を利用して類似度計算を行っている．\n",
        "Numpy配列の演算では，配列の各要素に対して同一の演算を行うことが可能となる．\n",
        "例えば，`img1 - img2`では，`img1`の各要素と`img2`の各要素の減算を行なっており，`diff**2`では各要素の2乗を計算している．\n",
        "Numpy配列の演算を用いることで，これまでに行なってきたfor文で一つづつ計算するよりも高速に計算することが可能となる．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZBE-fPcHhGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "def ssd(img1, img2):\n",
        "  img1 = np.float32(img1.flatten())\n",
        "  img2 = np.float32(img2.flatten())\n",
        "\n",
        "  diff = img1 - img2\n",
        "  ssd_val = np.sum(diff**2)\n",
        "  return ssd_val\n",
        "\n",
        "  \n",
        "def sad(img1, img2):\n",
        "  img1 = np.float32(img1.flatten())\n",
        "  img2 = np.float32(img2.flatten())\n",
        "  \n",
        "  sad_val = np.sum(np.abs(img1 - img2))\n",
        "  return sad_val\n",
        "\n",
        "\n",
        "def norm_cross_correlation(img1, img2):\n",
        "  img1 = np.float32(img1.flatten())\n",
        "  img2 = np.float32(img2.flatten())\n",
        "  \n",
        "  sum1 = np.sum(img1**2)\n",
        "  sum2 = np.sum(img2**2)\n",
        "  sum_prod = np.sum(img1 * img2)\n",
        "  ncc_val = sum_prod / math.sqrt(sum1 * sum2)\n",
        "  return ncc_val\n",
        "\n",
        "\n",
        "def zeromean_norm_cross_correlation(img1, img2):\n",
        "  img1 = np.float32(img1.flatten())\n",
        "  img2 = np.float32(img2.flatten())\n",
        "\n",
        "  mean1 = np.mean(img1)\n",
        "  mean2 = np.mean(img2)\n",
        "\n",
        "  subtract_mean1 = img1 - mean1\n",
        "  subtract_mean2 = img2 - mean2\n",
        "\n",
        "  sum1 = np.sum(subtract_mean1**2)\n",
        "  sum2 = np.sum(subtract_mean2**2)\n",
        "\n",
        "  sum_prod = np.sum(subtract_mean1 * subtract_mean2)\n",
        "\n",
        "  zm_ncc_val = sum_prod / math.sqrt(sum1 * sum2)\n",
        "  return zm_ncc_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-01hn-eVe3JF",
        "colab_type": "text"
      },
      "source": [
        "次に，指定した画像とテンプレートでテンプレートマッチングを行うための関数`matching_template`を定義する．\n",
        "\n",
        "この関数では，探索したい元画像とテンプレートを引数として入力する．\n",
        "また，第3引数の`metric`は，使用する類似尺度を指定する．\n",
        "`matching_template`関数では，上で定義した類似尺度の**関数を引数として入力**する．これにより関数中の`metric(...)`において，引数で指定した類似尺度を計算するための関数を用いて類似度計算を行うことができる．\n",
        "第4引数はもっとも類似度が高い座標を求めるために，最小値（最大値）を探すかどうかを指定する引数である．\n",
        "類似尺度によって，最も低い（最も高い）箇所が探索結果となる．\n",
        "そのため，第3引数で指定した類似尺度に合わせて最小値または最大値の座標のどちらを求めるかを指定する．\n",
        "`find_min=True`となっているのは，デフォルト引数であり．関数を使用する際に，この引数を記述しない場合は，`True`がデフォルト値として使用されることを示している．\n",
        "\n",
        "画像，テンプレート，尺度等を指定したのち，テンプレートマッチングを行う．\n",
        "\n",
        "まず，類似度を保存するための配列`template_socre`を用意する．\n",
        "その後，for文で1領域ごとに類似度を計算し，その結果を保存する．\n",
        "類似度の計算が全ての領域で終わると，`find_min`に従って，類似度が最小値または最大値の座標を求める．\n",
        "`argmin`関数は要素の値が最小となる箇所のインデックスを計算する関数であるが，通常は1次元配列に対して使用するものであり．2次元配列に対するインデックスを計算することができない．\n",
        "ここでは`unravel_index`関数を用いることで，2次元配列のまま最小値（最大値）のインデックスを計算している．\n",
        "\n",
        "得られた座標は左上の座標であり，領域を指定するため，右下の座標をテンプレートサイズから計算し，\n",
        "\n",
        "1. 探索した類似度のマップ\n",
        "2. マッチング結果の左上座標\n",
        "3. マッチング結果の右下座標\n",
        "\n",
        "を返す．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q36ea5kYUadG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def matching_template(img, template, metric, find_min=True):\n",
        "  h, w = img.shape\n",
        "  ht, wt = template.shape\n",
        "  template_score = np.zeros([h - ht, w - wt], dtype=np.float32)\n",
        "\n",
        "  for y in range(h - ht):\n",
        "    for x in range(w - wt):\n",
        "      template_score[y, x] = metric(img[y:y+ht, x:x+wt], template)\n",
        "  \n",
        "  if find_min:\n",
        "    top_left = np.unravel_index(np.argmin(template_score), template_score.shape)\n",
        "  else:\n",
        "    top_left = np.unravel_index(np.argmax(template_score), template_score.shape)\n",
        "\n",
        "  bottom_right = (top_left[0] + ht, top_left[1] + wt)\n",
        "  return template_score, top_left[::-1], bottom_right[::-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoC-i7J1KzTd",
        "colab_type": "text"
      },
      "source": [
        "### Sum of Squared Difference (SSD)\n",
        "\n",
        "SSDを類似尺度として用いた場合のテンプレートマッチングを行う．\n",
        "テンプレートマッチングの処理は，すでに上の関数で全て定義してあるため．`matching_template`関数の第3引数を`ssd`と指定することで計算が可能である．\n",
        "また，SSDは値が小さい場合に類似度が高くなるため，第4引数の`find_min`をTrueにする必要があるが，デフォルト値ですでに`True`が指定されているため，記述していない．\n",
        "\n",
        "マッチング結果が得られたら，`rectangle`関数を用いて矩形を描画し，結果を表示する．\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d39pgKUUmdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = img2.copy()\n",
        "template = img1.copy()\n",
        "\n",
        "ssd_score, top_left_coord, bottom_right_coord = matching_template(img, template, ssd)\n",
        "\n",
        "print(\"found coordinate (x, y)\")\n",
        "print(\"   top-left    :\", top_left_coord)\n",
        "print(\"   bottom-right:\", bottom_right_coord)\n",
        "\n",
        "cv2.rectangle(img, top_left_coord, bottom_right_coord, 255, 5)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(121), plt.imshow(ssd_score, cmap=\"jet\")\n",
        "plt.colorbar()\n",
        "plt.subplot(122), plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MAxnhN4VnMg",
        "colab_type": "text"
      },
      "source": [
        "### Sum of Absolute Difference (SAD)\n",
        "\n",
        "SADもSDDと同様の手順でテンプレートマッチングを行う．\n",
        "そのため，`matching_template`関数の第3引数を`sad`に変更するだけで異なる類似尺度での探索が可能である．\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOGA3dR_VnRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = img2.copy()\n",
        "template = img1.copy()\n",
        "\n",
        "sad_score, top_left_coord, bottom_right_coord = matching_template(img, template, sad)\n",
        "\n",
        "print(\"found coordinate (x, y)\")\n",
        "print(\"   top-left    :\", top_left_coord)\n",
        "print(\"   bottom-right:\", bottom_right_coord)\n",
        "\n",
        "cv2.rectangle(img, top_left_coord, bottom_right_coord, 255, 5)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(121), plt.imshow(sad_score, cmap=\"jet\")\n",
        "plt.colorbar()\n",
        "plt.subplot(122), plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0AZ0cB1VnV_",
        "colab_type": "text"
      },
      "source": [
        "### 正規化相互相関（Normalized Cross-Correlation）\n",
        "\n",
        "正規化相互相関も，SSDおよびSADと同様の手順で実行することが可能であるが，\n",
        "この類似尺度では最も値が高い箇所をマッチング結果として探索する必要があるため，第4引数を`find_min=False`と指定して，最大値を探すようにする必要がある．\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGlASLJwVnaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = img2.copy()\n",
        "template = img1.copy()\n",
        "\n",
        "ncc_score, top_left_coord, bottom_right_coord = matching_template(img, template, norm_cross_correlation, find_min=False)\n",
        "\n",
        "print(\"found coordinate (x, y)\")\n",
        "print(\"   top-left    :\", top_left_coord)\n",
        "print(\"   bottom-right:\", bottom_right_coord)\n",
        "\n",
        "cv2.rectangle(img, top_left_coord, bottom_right_coord, 255, 5)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(121), plt.imshow(ncc_score, cmap=\"jet\")\n",
        "plt.colorbar()\n",
        "plt.subplot(122), plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaP-e0RgVnfH",
        "colab_type": "text"
      },
      "source": [
        "### ゼロ平均相互相関係数（Zero-means Normalized Cross-Correlation）\n",
        "\n",
        "ゼロ平均相互相関係数についても，正規化相互相関と同様の手順で実行が可能である．\n",
        "\n",
        "ゼロ平均相互相関係数の尺度を用いた場合．正規化相互相関よりもマッチングする箇所とそうでない箇所の類似度の差が大きいことが確認できる．\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwXmt9ryVnjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = img2.copy()\n",
        "template = img1.copy()\n",
        "\n",
        "zm_ncc_score, top_left_coord, bottom_right_coord = matching_template(img, template, zeromean_norm_cross_correlation, find_min=False)\n",
        "\n",
        "print(\"found coordinate (x, y)\")\n",
        "print(\"   top-left    :\", top_left_coord)\n",
        "print(\"   bottom-right:\", bottom_right_coord)\n",
        "\n",
        "cv2.rectangle(img, top_left_coord, bottom_right_coord, 255, 5)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(121), plt.imshow(zm_ncc_score, cmap=\"jet\")\n",
        "plt.colorbar()\n",
        "plt.subplot(122), plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2SibhTva8GC",
        "colab_type": "text"
      },
      "source": [
        "## 粗密探索\n",
        "\n",
        "テンプレートマッチングは探索する画像の大きさ等に応じて処理時間が増加する．\n",
        "そのため，大きな画像に対してマッチングを行う場合には，効率的な探索を行う必要がある．\n",
        "\n",
        "効率的なテンプレートマッチングの方法として粗密探索がある．\n",
        "粗密探索では，はじめに，低解像度の小さな画像で探索を行う．\n",
        "その結果得られた座標の近傍のみで，高解像度な探索を行うことで効率化を行う方法である．\n",
        "\n",
        "まずはじめに，従来の全探索（全ての領域で類似度計算を行う方法）の処理時間を計測する．\n",
        "時間の計測には`time`モジュールの`time`関数（`time.time()`）使用する．\n",
        "`time`関数は，この関数が実行された際の時刻を保存する関数である．\n",
        "そのため，テンプレートマッチングの開始前後の時刻を記録して，その差分を計算することで処理時間を計測することが可能となる．\n",
        "\n",
        "テンプレートマッチングの実行には，4つの類似尺度のうち，最も計算時間がかかると思われる，ゼロ平均相互相関係数を使用する．\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo7vh3lua8Kw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "img = img2.copy()\n",
        "template = img1.copy()\n",
        "\n",
        "time_start1 = time.time()\n",
        "zm_ncc_score, top_left_coord, bottom_right_coord = matching_template(img, template, zeromean_norm_cross_correlation, find_min=False)\n",
        "time_end1 = time.time()\n",
        "print(\"found top-left coordinate:\", top_left_coord)\n",
        "print(\"processing time:\", time_end1 - time_start1, \"[s]\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ9y2PekVgaN",
        "colab_type": "text"
      },
      "source": [
        "次に粗密探索によるテンプレートマッチングを実行し，処理時間を計測する．\n",
        "\n",
        "はじめに，前準備として，低解像度の画像とテンプレート（`img_small`, `template_small`）を用意する．\n",
        "ここでは，元のサイズの1/4のサイズにリサイズする．\n",
        "\n",
        "`time`関数で時間を計測し，低解像度画像でテンプレートマッチングを行う．\n",
        "その後，低解像度画像で得られた結果に対応する領域を元画像から抽出する．\n",
        "そして，対応領域のみを用いてテンプレートマッチングを行い，得られた結果を元画像の座標へと変換してマッチングを終了する．\n",
        "\n",
        "実行の結果，上で実行した全探索に比べて大幅に処理時間を削減できていることがわかる．\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFIRjc1siWci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = img2.copy()\n",
        "template = img1.copy()\n",
        "ht, wt = template.shape\n",
        "\n",
        "# 画像を1/4のサイズにリサイズ\n",
        "img_small = cv2.resize(img, None, fx=0.25, fy=0.25)\n",
        "template_small = cv2.resize(template, None, fx=0.25, fy=0.25)\n",
        "\n",
        "time_start2 = time.time()\n",
        "# 低解像度画像でテンプレートマッチング\n",
        "score_s, tl_s, br_s = matching_template(img_small, template_small, zeromean_norm_cross_correlation, find_min=False)\n",
        "print(\"found top-left coordinate (small)   :\", tl_s)\n",
        "\n",
        "# 低解像度画像に対応する領域を元画像から抽出\n",
        "img_trimmed = img[tl_s[0]*4:(tl_s[0]+1)*4+ht, tl_s[1]*4:(tl_s[1]+1)*4+wt]\n",
        "\n",
        "# 対応領域を抽出した画像でテンプレートマッチング\n",
        "score, tl, br = matching_template(img_trimmed, template, zeromean_norm_cross_correlation, find_min=False)\n",
        "print(\"found top-left coordinate (trimmed) :\", tl)\n",
        "\n",
        "# 得られた座標を元画像中の座標に変換\n",
        "top_left = (tl[0] + tl_s[0]*4, tl[1] + tl_s[1]*4)\n",
        "bottom_right = (br[0] + tl_s[0]*4, br[1] + tl_s[1]*4)\n",
        "print(\"found top-left coordinate (original):\", top_left)\n",
        "time_end2 = time.time()\n",
        "print(\"processing time:\", time_end2 - time_start2, \"[s]\")\n",
        "\n",
        "# 結果の描画\n",
        "cv2.rectangle(img_small, tl_s, br_s, 255, 1)\n",
        "cv2.rectangle(img, top_left, bottom_right, 255, 5)\n",
        "\n",
        "# 表示\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(121), plt.imshow(score_s, cmap=\"jet\")\n",
        "plt.colorbar()\n",
        "plt.subplot(122), plt.imshow(img_small, cmap=\"gray\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(121), plt.imshow(score, cmap=\"jet\")\n",
        "plt.colorbar()\n",
        "plt.subplot(122), plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svRqPEAyJCqM",
        "colab_type": "text"
      },
      "source": [
        "## OpenCVを用いた方法\n",
        "\n",
        "OpenCVにはテンプレートマッチングを行うための，`matchTemplate`関数がある．\n",
        "この関数では，いくつかの類似尺度を使用することができる．\n",
        "\n",
        "以下では，`matchTemplate`関数を用いて，それぞれの類似尺度を用いた場合の結果を示す．\n",
        "なお，それぞれの類似尺度の詳細については[OpenCVのドキュメント](https://docs.opencv.org/master/df/dfb/group__imgproc__object.html)を参照すること．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGIsqeqtfmu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "template = img1.copy()\n",
        "h, w = template.shape\n",
        "\n",
        "# 6つの方法で比較を行う\n",
        "methods = ['cv2.TM_SQDIFF',         # 差分相関 (SSD)\n",
        "           'cv2.TM_SQDIFF_NORMED',  # 正規化差分相関\n",
        "           'cv2.TM_CCORR',          # 相互相関\n",
        "           'cv2.TM_CCORR_NORMED',   # 正規化相互相関\n",
        "           'cv2.TM_CCOEFF',         # 相関係数\n",
        "           'cv2.TM_CCOEFF_NORMED']  # 正規化相関係数\n",
        "\n",
        "# 上で定義した方法を一つづつ実行\n",
        "for meth in methods:\n",
        "  img = img2.copy()\n",
        "  method = eval(meth)\n",
        "\n",
        "  # テンプレートマッチング\n",
        "  res = cv2.matchTemplate(img, template, method)\n",
        "  min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
        "\n",
        "  # メソッドが TM_SQDIFF または TM_SQDIFF_NORMED の場合は，最小値を取る\n",
        "  if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
        "    top_left = min_loc\n",
        "  else:\n",
        "    top_left = max_loc\n",
        "  bottom_right = (top_left[0] + w, top_left[1] + h)\n",
        "\n",
        "  cv2.rectangle(img,top_left, bottom_right, 255, 5)\n",
        "\n",
        "  plt.figure(figsize=(12, 4))\n",
        "  plt.subplot(121), plt.imshow(res, cmap='jet')\n",
        "  plt.title('Matching Score')\n",
        "  plt.colorbar()\n",
        "  plt.subplot(122), plt.imshow(img, cmap='gray')\n",
        "  plt.title('Detected Point')\n",
        "  plt.suptitle(meth)\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLK5van7YX_i",
        "colab_type": "text"
      },
      "source": [
        "## 課題\n",
        "\n",
        "* ヒートマップを観察して，考察すること\n",
        "* 各手法の処理時間を比較し，考察すること\n",
        "* 粗密探索において，低解像度画像のサイズを変更し，処理時間の違いを確認すること"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4TCc0sKFkfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}