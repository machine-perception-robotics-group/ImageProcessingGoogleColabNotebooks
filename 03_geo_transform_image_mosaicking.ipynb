{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/machine-perception-robotics-group/ImageProcessingGoogleColabNotebooks/blob/master/03_geo_transform_image_mosaicking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t0xuHuVzr-Ep"
      },
      "source": [
        "# 03. 画像の幾何変換，イメージモザイク\n",
        "\n",
        "講義で説明する画像処理の方法について，google colaboratoryを利用して演習する．\n",
        "google colaboratoryは，クラウドで実行する Jupyter ノートブック環境である.\n",
        "google coraboratoryについては，[ここ](https://www.tdi.co.jp/miso/google-colaboratory-gpu)や[ここ](https://www.codexa.net/how-to-use-google-colaboratory/)を参考にすること．\n",
        "\n",
        "下記のプログラムを実行すると，画像の幾何変換とイメージモザイクを行う．\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7Bbaet2C4U7F"
      },
      "source": [
        "## 準備\n",
        "プログラムの動作に必要なデータをダウンロードし，zipファイルを解凍する．\n",
        "`!`で始まるコマンドはPythonではなく，Linux（Ubuntu）のコマンドを実行している．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3NYtuZtndzQ4"
      },
      "outputs": [],
      "source": [
        "!wget -q https://raw.githubusercontent.com/machine-perception-robotics-group/ImageProcessingGoogleColabNotebooks/master/image1.zip\n",
        "!unzip -q image1.zip\n",
        "!ls\n",
        "!ls ./image1/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mkwrQ8dwa2sZ"
      },
      "source": [
        "## 画像の読み込みと表示\n",
        "必要なパッケージをインポートし，画像を表示する．\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YFl5XkzmZCg9"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "img1 = cv2.imread('./image1/woman-g.jpg', 2)\n",
        "plt.imshow(img1, cmap = \"gray\", clim=(0, 255))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dSN9s3p-owyQ"
      },
      "source": [
        "## 座標変換\n",
        "\n",
        "ここでは，画像の座標変換を行う．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_v46kIGmo7zy"
      },
      "source": [
        "### 平行移動\n",
        "\n",
        "平行移動は，対応する画素値を指定した移動量従い，対応する配列の要素に代入することで実現される．\n",
        "\n",
        "まず，変換後の画像データを保存するための配列を準備し，x, y方向それぞれの移動量を指定する．\n",
        "\n",
        "その後，移動量に従い，画素値を代入することで，平行移動を行う．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FXxVb7VBY6iY"
      },
      "outputs": [],
      "source": [
        "img = img1.copy()\n",
        "height, width = img.shape\n",
        "\n",
        "# 変換後の画像データを保存するための配列を準備\n",
        "img_translated = np.ones(img.shape, dtype=np.uint8) * 255\n",
        "\n",
        "# x, y方向それぞれの移動量を指定\n",
        "t_x = 100\n",
        "t_y = 10\n",
        "\n",
        "for y in range(height):\n",
        "  for x in range(width):\n",
        "    if 0 < y+t_y < height and 0 < x+t_x < width:\n",
        "      img_translated[y+t_y, x+t_x] = img[y, x]\n",
        "\n",
        "plt.imshow(img_translated, cmap=\"gray\", clim=(0, 255))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-M2zNUeQo-yw"
      },
      "source": [
        "### 拡大縮小\n",
        "\n",
        "拡大縮小では，画像座標系の原点（0, 0）を基準に指定した倍率に画像を拡大縮小する．\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FwOw0CsMrhY8"
      },
      "outputs": [],
      "source": [
        "img = img1.copy()\n",
        "height, width = img.shape\n",
        "\n",
        "# 変換後の画像データを保存するための配列を準備\n",
        "img_translated = np.ones(img.shape, dtype=np.uint8) * 255\n",
        "\n",
        "# x, y方向それぞれの拡大縮小率を指定\n",
        "Sx = 1.5\n",
        "Sy = 1.5\n",
        "\n",
        "for y in range(height):\n",
        "  for x in range(width):\n",
        "    if 0 < y*Sy < height and 0 < x*Sx < width:\n",
        "      img_translated[int(y*Sy), int(x*Sx)] = img[y, x]\n",
        "\n",
        "plt.imshow(img_translated, cmap=\"gray\", clim=(0, 255))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7yeL5idOpBwO"
      },
      "source": [
        "### 回転\n",
        "\n",
        "画像の回転は，画像座標系の原点を軸として，指定した角度に画像を回転させる．\n",
        "\n",
        "`theta`で回転角度を指定する．\n",
        "その後，`math.sin`, `math.cos`関数を用いて，指定した角度に対するsin, cosを計算する．\n",
        "この時，`math.sin`, `math.cos`関数へ入力する角度は弧度法に基づくため，`math.radian`関数を用いて，度数法で表現した角度を変換して入力する．\n",
        "\n",
        "得られたsin, cosを用いて，変換した座標に画素値を代入することで，画像の回転を行う．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "DXUNO_8nwBow"
      },
      "outputs": [],
      "source": [
        "img = img1.copy()\n",
        "height, width = img.shape\n",
        "\n",
        "# 変換後の画像データを保存するための配列を準備\n",
        "img_translated = np.ones(img.shape, dtype=np.uint8) * 255\n",
        "\n",
        "# 回転角度を指定\n",
        "theta = -15\n",
        "sin_th = math.sin(math.radians(theta))\n",
        "cos_th = math.cos(math.radians(theta))\n",
        "\n",
        "for y in range(height):\n",
        "  for x in range(width):\n",
        "    if 0 < (x*sin_th + y*cos_th) < height and 0 < (x*cos_th - y*sin_th) < width:\n",
        "      img_translated[int(x*sin_th + y*cos_th), int(x*cos_th - y*sin_th)] = img[y, x]\n",
        "\n",
        "plt.imshow(img_translated, cmap=\"gray\", clim=(0, 255))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BBiT1PsRpE59"
      },
      "source": [
        "### スキュー\n",
        "\n",
        "スキューでは，指定した角度に画像を傾けるような変換を行う．\n",
        "以下では，水平方向・垂直方向のスキューを行う．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9bmqmhqGXceo"
      },
      "source": [
        "#### 水平方向のスキュー"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4IXZy5Z_0mVn"
      },
      "outputs": [],
      "source": [
        "img = img1.copy()\n",
        "height, width = img.shape\n",
        "\n",
        "# 変換後の画像データを保存するための配列を準備\n",
        "img_translated = np.ones(img.shape, dtype=np.uint8) * 255\n",
        "\n",
        "# 水平方向のスキューの角度を指定\n",
        "theta = 30\n",
        "tan_th = math.tan(math.radians(theta))\n",
        "\n",
        "for y in range(height):\n",
        "    for x in range(width):\n",
        "      if 0 < int(x + y*tan_th) < width:\n",
        "        img_translated[y, int(x + y*tan_th)] = img[y, x]\n",
        "\n",
        "plt.imshow(img_translated, cmap=\"gray\", clim=(0, 255))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hVO4hMMGXf34"
      },
      "source": [
        "#### 垂直方向のスキュー"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FiPStDW4Xf76"
      },
      "outputs": [],
      "source": [
        "img = img1.copy()\n",
        "height, width = img.shape\n",
        "\n",
        "# 変換後の画像データを保存するための配列を準備\n",
        "img_translated = np.ones(img.shape, dtype=np.uint8) * 255\n",
        "\n",
        "# 垂直方向のスキューの角度を指定\n",
        "theta = 30\n",
        "tan_th = math.tan(math.radians(theta))\n",
        "\n",
        "for y in range(height):\n",
        "    for x in range(width):\n",
        "      if 0 < int(x*tan_th + y) < height:\n",
        "        img_translated[int(x*tan_th + y), x] = img[y, x]\n",
        "\n",
        "plt.imshow(img_translated, cmap=\"gray\", clim=(0, 255))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9r7R1MuM7dTc"
      },
      "source": [
        "### アフィン変換\n",
        "\n",
        "アフィン変換は同次座標を導入した3x3の行列で任意の画像変換を行う方法である．\n",
        "\n",
        "以下では，アフィン変換を用いて複数の画像変換を行う．\n",
        "具体的には\n",
        "1. 平行移動\n",
        "2. 拡大縮小\n",
        "3. 回転\n",
        "4. 平行移動（1. とは逆方向）\n",
        "\n",
        "を連続して処理する．\n",
        "\n",
        "まず，各変換を行うためのアフィン行列（`T1`, `S`, `R`, `T2`）を定義する．\n",
        "各行列はNumpyの`matrix`で定義を行う．これまでに使用していたNumpyの`array`とは異なり，掛け算等の演算を行う際には，行列演算に従った計算を行う．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XUnZXQedezJW"
      },
      "outputs": [],
      "source": [
        "# 画像の中心を原点に移動するための平行移動のアフィン行列を定義\n",
        "t_x = -320\n",
        "t_y = -240\n",
        "T1 = np.matrix([[1, 0, t_x],\n",
        "                [0, 1, t_y],\n",
        "                [0, 0,   1]])\n",
        "\n",
        "# 拡大縮小のアフィン行列を定義\n",
        "s_x = 0.5\n",
        "s_y = 0.5\n",
        "S = np.matrix([[s_x, 0, 0],\n",
        "               [0, s_y, 0],\n",
        "               [0,   0, 1]])\n",
        "\n",
        "# 回転のアフィン行列を定義\n",
        "theta = -45\n",
        "sin_th = math.sin(math.radians(theta))\n",
        "cos_th = math.cos(math.radians(theta))\n",
        "R = np.matrix([[cos_th, -sin_th, 0],\n",
        "               [sin_th,  cos_th, 0],\n",
        "               [     0,       0, 1]])\n",
        "\n",
        "# 変換した画像を元の座標に移動するための平行移動のアフィン行列を定義（T1とは逆方向の平行移動）\n",
        "T2 = np.matrix([[1, 0, -t_x],\n",
        "                [0, 1, -t_y],\n",
        "                [0, 0,    1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2lWzPba7NcGp"
      },
      "source": [
        "#### 一つづつアフィン変換を行う方法\n",
        "\n",
        "以下では，上で定義したアフィン行列（`T1`, `S`, `R`, `T2`）を一つづつ用いて，順番に画像変換を行う．\n",
        "\n",
        "画像変換を順番に適用することで，任意の画像変換を行うことができる．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "nMa42DMjga8w"
      },
      "outputs": [],
      "source": [
        "# 変換する画像をコピー\n",
        "img= img1.copy()\n",
        "height, width = img.shape\n",
        "\n",
        "# 平行移動\n",
        "img_translated1 = np.ones(img.shape, dtype=np.uint8) * 255\n",
        "for y in range(height):\n",
        "  for x in range(width):\n",
        "    x1, y1, _ = T1 * np.matrix([[x], [y], [1]])\n",
        "    if 0 < int(x1) < width and 0 < int(y1) < height:\n",
        "      # 元画像を平行移動する\n",
        "      img_translated1[int(y1), int(x1)] = img[y, x]\n",
        "  \n",
        "plt.imshow(img_translated1, cmap=\"gray\", clim=(0, 255)), plt.title(\"parallel translation 1\")\n",
        "plt.show()\n",
        "\n",
        "# 拡大縮小\n",
        "img_translated2 = np.ones(img.shape, dtype=np.uint8) * 255\n",
        "for y in range(height):\n",
        "  for x in range(width):\n",
        "    x1, y1, _ = S * np.matrix([[x], [y], [1]])\n",
        "    if 0 < int(x1) < width and 0 < int(y1) < height:\n",
        "      # 平行移動した画像を拡大縮小する\n",
        "      img_translated2[int(y1), int(x1)] = img_translated1[y, x]\n",
        "  \n",
        "plt.imshow(img_translated2, cmap=\"gray\", clim=(0, 255)), plt.title(\"scaling\")\n",
        "plt.show()\n",
        "\n",
        "# 回転\n",
        "img_translated3 = np.ones(img.shape, dtype=np.uint8) * 255\n",
        "for y in range(height):\n",
        "  for x in range(width):\n",
        "    x1, y1, _ = R * np.matrix([[x], [y], [1]])\n",
        "    if 0 < int(x1) < width and 0 < int(y1) < height:\n",
        "      # 拡大縮小した画像を回転させる\n",
        "      img_translated3[int(y1), int(x1)] = img_translated2[y, x]\n",
        "plt.imshow(img_translated3, cmap=\"gray\", clim=(0, 255)), plt.title(\"rotation\")\n",
        "plt.show()\n",
        "\n",
        "# 平行移動2\n",
        "img_translated4 = np.ones(img.shape, dtype=np.uint8) * 255\n",
        "for y in range(height):\n",
        "  for x in range(width):\n",
        "    x1, y1, _ = T2 * np.matrix([[x], [y], [1]])\n",
        "    if 0 < int(x1) < width and 0 < int(y1) < height:\n",
        "      # 回転した画像を平行移動する\n",
        "      img_translated4[int(y1), int(x1)] = img_translated3[y, x]\n",
        "plt.imshow(img_translated4, cmap=\"gray\", clim=(0, 255)), plt.title(\"parallel translation 2\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QCzhBCLrk1mg"
      },
      "source": [
        "#### 複数の変換を一つに行列で一度に行う方法\n",
        "\n",
        "上では，アフィン変換を一つづつ適用した．\n",
        "\n",
        "ここでは，複数のアフィン行列を一つの行列にして，変換を行う．\n",
        "\n",
        "行列`H`に適用したい変換のアフィン行列の積を計算する．\n",
        "このとき，先に適用する変換の行列を右，その後適用する変換の行列を左として積を計算することで，任意の順番の変換を行うことができる．\n",
        "\n",
        "変換の結果を確認すると，上記と同様の手順ではあるが，こちらの方法では，画像が領域外にはみ出す影響が無く，画像が欠けることなく変換できている．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BM_ovqJnk3Nr"
      },
      "outputs": [],
      "source": [
        "# 行列をまとめる\n",
        "H = T2 * R * S * T1\n",
        "\n",
        "img_trans_all = np.ones(img.shape, dtype=np.uint8) * 255\n",
        "\n",
        "for y in range(height):\n",
        "  for x in range(width):\n",
        "    x1, y1, _ = H * np.matrix([[x], [y], [1]])\n",
        "    if 0 < int(x1) < width and 0 < int(y1) < height:\n",
        "      img_trans_all[int(y1), int(x1)] = img[y, x]\n",
        "  \n",
        "plt.imshow(img_trans_all, cmap=\"gray\", clim=(0, 255)), plt.title(\"affine transform (all)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "roqbC9SRlgZC"
      },
      "source": [
        "#### OpenCVを用いたアフィン変換\n",
        "\n",
        "OpenCVには`warpAffine`という任意のアフィン行列を用いて画像を変換するための関数が用意されている．\n",
        "以下では，`warpAffine`関数を用いたアフィン変換を行う．\n",
        "`warpAffine`関数では，第1引数に変換する画像，第2引数にアフィン行列を指定する．第3引数は出力する画像のサイズを示している．\n",
        "\n",
        "まず，上で作成したアフィン行列`H`を用いて，アフィン変換を行う．\n",
        "同様の変換が実現できていることが確認できる．\n",
        "\n",
        "また，OpenCVの`getRotationMatrix2D`関数を用いてアフィン行列を作成し，変換を行うことも可能である．\n",
        "`getRotationMatrix2D`関数の詳細については割愛する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "e6HWbhbF7gHq"
      },
      "outputs": [],
      "source": [
        "img= img1.copy()\n",
        "height, width = img.shape\n",
        "\n",
        "# 上で作成した行列Hを用いてアフィン変換\n",
        "img_translated1 = cv2.warpAffine(img, H[0:2, :], (width, height))\n",
        "plt.imshow(img_translated1, cmap=\"gray\", clim=(0, 255))\n",
        "plt.title(\"affine transform 1\")\n",
        "plt.show()\n",
        "\n",
        "# OpenCVの関数を用いて変換行列を作成した場合\n",
        "mat = cv2.getRotationMatrix2D((360, 240), 45, 0.5)\n",
        "img_translated2 = cv2.warpAffine(img, mat, (width, height))\n",
        "plt.imshow(img_translated2, cmap=\"gray\", clim=(0, 255))\n",
        "plt.title(\"affine transform 2\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0mZMOBqyvZ7e"
      },
      "source": [
        "## イメージモザイク\n",
        "\n",
        "イメージモザイク（モザイキング）は画像の幾何変換を用いて，画像をつなぎ合わせる処理である．\n",
        "以下では，イメージモザイクにより，2枚の画像をつなぎ合わせる．\n",
        "\n",
        "まず，イメージモザイクに使用する画像を読み込む．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WVhRoQpaltse"
      },
      "outputs": [],
      "source": [
        "img1 = cv2.imread('./image1/Blackboard1.jpg')\n",
        "img2 = cv2.imread('./image1/Blackboard2.jpg')\n",
        "img3 = cv2.imread('./image1/Blackboard3.jpg')\n",
        "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
        "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
        "img3 = cv2.cvtColor(img3, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.figure(figsize=(8, 16))\n",
        "plt.subplot(311),plt.imshow(img1),plt.title('img1')\n",
        "plt.subplot(312),plt.imshow(img2),plt.title('img2')\n",
        "plt.subplot(313),plt.imshow(img3),plt.title('img3')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OstNKcFun1eS"
      },
      "source": [
        "#### 対応点の決定\n",
        "\n",
        "次に，基準となる対応点を求めます．\n",
        "今回は画像中の黒板の中で特徴的な部分を対応点として，それぞれの画像の対する座標を指定します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "kD7wkcbwwDl4"
      },
      "outputs": [],
      "source": [
        "xy1 = np.array([[1378, 441],\n",
        "                [1375, 532],\n",
        "                [1540, 621],\n",
        "                [1496, 446]])\n",
        "\n",
        "xy2 = np.array([[ 953, 432],\n",
        "                [ 950, 520],\n",
        "                [1107, 607],\n",
        "                [1066, 438]])\n",
        "\n",
        "xy3 = np.array([[ 439, 421],\n",
        "                [ 435, 512],\n",
        "                [ 594, 600],\n",
        "                [ 554, 431]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JXeFyK5CSdmx"
      },
      "source": [
        "指定した対応点を描画します．\n",
        "同じ色のマーカーが同じ対応点を表しています．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "oSeZKvAqCoi9"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 16))\n",
        "\n",
        "plt.subplot(311)\n",
        "plt.imshow(img1)\n",
        "plt.scatter(xy1[:,0], xy1[:,1], marker='x', c=range(4), cmap='rainbow')\n",
        "\n",
        "plt.subplot(312)\n",
        "plt.imshow(img2)\n",
        "plt.scatter(xy2[:,0], xy2[:,1], marker='x', c=range(4), cmap='rainbow')\n",
        "\n",
        "plt.subplot(313)\n",
        "plt.imshow(img3)\n",
        "plt.scatter(xy3[:,0], xy3[:,1], marker='x', c=range(4), cmap='rainbow')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1SZNSgHYStdy"
      },
      "source": [
        "#### 幾何変換の推定\n",
        "\n",
        "指定した対応点を用いて，幾何変換の推定を行います．\n",
        "今回は，`img1`を基準として，`img3`を変換するための行列を求めます．\n",
        "\n",
        "行列の推定には，OpenCVの`getPerspectiveTransform`関数を使用します．\n",
        "`getPerspectiveTransform`関数では，4点の対応点から変換行列を計算します．\n",
        "\n",
        "推定した行列`P`とscikit-imageの`warp`関数を用いて，画像を変換します．\n",
        "\n",
        "その後，変換後の画像と基準となる`img1`をつなぎ合わせ，1枚の画像とします．\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2ztXc_UMEoXc"
      },
      "outputs": [],
      "source": [
        "from skimage.transform import warp\n",
        "\n",
        "# 変換行列の計算\n",
        "P = cv2.getPerspectiveTransform(xy1.astype(np.float32), xy3.astype(np.float32))\n",
        "\n",
        "# 画像の変換\n",
        "f_stitched = warp(img3, P, output_shape=(1200, 2800))\n",
        "f_stitched = f_stitched * 255\n",
        "f_stitched = f_stitched.astype(np.uint8)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.imshow(f_stitched)\n",
        "plt.show()\n",
        "\n",
        "# 変換した画像と基準となる画像を合成する\n",
        "h, w = img1.shape[:2]\n",
        "f_stitched[0:h, 0:w, :] = img1\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.imshow(f_stitched)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2gEGPcS3yXdz"
      },
      "source": [
        "## 課題\n",
        "\n",
        "* 各座標変換の変数を変更し，どのように変化するか確認すること\n",
        "* イメージモザイキングの対応点の一部や使用する画像（`img2`）を変更すると，合成結果がどのように変化するか確認すること"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "yFYxLPOtu2DP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "03.geo_transform_image_mosaicking",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
