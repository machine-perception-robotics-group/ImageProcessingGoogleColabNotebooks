{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_hough_fourier_transform",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/machine-perception-robotics-group/ImageProcessingGoogleColabNotebooks/blob/master/04_hough_fourier_transform.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Bbaet2C4U7F",
        "colab_type": "text"
      },
      "source": [
        "# 04. ハフ変換，フーリエ変換\n",
        "\n",
        "講義で説明する画像処理の方法について，google colaboratoryを利用して演習する．\n",
        "google colaboratoryは，クラウドで実行する Jupyter ノートブック環境である.\n",
        "google coraboratoryについては，[ここ](https://www.tdi.co.jp/miso/google-colaboratory-gpu)や[ここ](https://www.codexa.net/how-to-use-google-colaboratory/)を参考にすること．\n",
        "\n",
        "下記のプログラムを実行すると，ハフ変換による直線や円の検出，フーリエ変換による画像の周波数領域表現の獲得，ローパスフィルタ，ハイパスフィルタを行う．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5YIWXOGbWpk",
        "colab_type": "text"
      },
      "source": [
        "## 準備\n",
        "プログラムの動作に必要なデータをダウンロードする．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NYtuZtndzQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q http://www.mprg.cs.chubu.ac.jp/Tutorial/ML_Lecture/tutorial_ip_2020/image1.zip\n",
        "!unzip -q image1.zip\n",
        "!ls\n",
        "!ls ./image1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkwrQ8dwa2sZ",
        "colab_type": "text"
      },
      "source": [
        "## 画像の読み込みと表示\n",
        "必要なパッケージをインポートし，画像を表示する．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YFl5XkzmZCg9",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "img1 = cv2.imread('./image1/coin.png', 0)\n",
        "img2 = cv2.imread('./image1/ipod.png', 0)\n",
        "img3 = cv2.imread('./image1/woman-t.jpg', 0)\n",
        "\n",
        "plt.imshow(img1, cmap=\"gray\")\n",
        "plt.show()\n",
        "plt.imshow(img2, cmap=\"gray\")\n",
        "plt.show()\n",
        "plt.imshow(img3, cmap=\"gray\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW1xNHVJMnDw",
        "colab_type": "text"
      },
      "source": [
        "## ハフ変換\n",
        "\n",
        "ハフ変換は画像中から直線や円を検出したい場合に用いられる方法である．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyvNozeQNNvh",
        "colab_type": "text"
      },
      "source": [
        "### 直線の検出\n",
        "\n",
        "ここでは，ハフ変換による直線の検出を行う．\n",
        "\n",
        "はじめにソーベルフィルタによるエッジの検出と検出したエッジの2値化を行う．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2JERdD1qDbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = img2.copy()\n",
        "\n",
        "# ソーベルフィルタによるエッジ検出\n",
        "img_sobel_x = cv2.Sobel(img, cv2.CV_32F, 1, 0, ksize=3)\n",
        "img_sobel_y = cv2.Sobel(img, cv2.CV_32F, 0, 1, ksize=3)\n",
        "img_sobel = np.sqrt(img_sobel_x**2 + img_sobel_y**2)\n",
        "img_sobel = np.abs(img_sobel)\n",
        "plt.imshow(img_sobel, cmap=\"gray\")\n",
        "plt.show()\n",
        "\n",
        "# 検出したエッジを二値化\n",
        "img_binary = img_sobel.copy()\n",
        "img_binary[img_sobel <= 200] = 0\n",
        "img_binary[img_sobel > 200] = 255\n",
        "plt.imshow(img_binary, cmap=\"gray\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYHi1pPlh4VT",
        "colab_type": "text"
      },
      "source": [
        "次に，検出したエッジを用いて，直線を検出する．\n",
        "\n",
        "検出にはOpenCVの`HoughLinesP`関数を使用する．\n",
        "`HoughLinesP`関数では，検出に使用する画像（今回は2値化したエッジ画像）と投票空間の距離と角度の分解能，最小の線分長，および2点が同一線分上にあると見なす場合に許容される最大距離を引数として入力する．\n",
        "\n",
        "`HoughLinesP`関数を適用した結果，検出した直線の情報が返され，`lines`に格納される．\n",
        "`lines`に格納された値を取り出し，直線を一つづつ描画する．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h97oBc2wPeip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 検出する最小の線分長\n",
        "minLineLength = 100\n",
        "# 2点が同一線分上にあると見なす場合に許容される最大距離\n",
        "maxLineGap = 10\n",
        "\n",
        "# 確率的ハフ変換を利用した線分検出\n",
        "lines = cv2.HoughLinesP(img_binary.astype(np.uint8), 1, np.pi/180, 60, minLineLength, maxLineGap)\n",
        "\n",
        "# 結果を描画するための画像を準備\n",
        "img_result = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "# 検出した線分を一つづつ描画\n",
        "for l in lines:\n",
        "  x1, y1, x2, y2 = l[0]\n",
        "  img_result = cv2.line(img_result, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "\n",
        "plt.imshow(img_result)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82wusixINGNh",
        "colab_type": "text"
      },
      "source": [
        "### 円の検出\n",
        "\n",
        "続いて，ハフ変換による円の検出を行う．\n",
        "\n",
        "円の検出には，OpenCVの`HoughCircles`関数を用いる．\n",
        "`HoughCircles`関数では，引数に，入力画像，使用するハフ変換の手法（`HOUGH_GRADIENT`），画像分解能に対する東方分解能の比率の逆数（分解能の粗さ），検出される円の中心同士の最小距離，キャニーのエッジ検出器のパラメータ，検出時の投票数の閾値，円の最小半径，最大半径を入力する．\n",
        "\n",
        "その後，検出した円を描画する．\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai8jHIruUrq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 円検出する画像を読み込んで，メディアンフィルタを適用する\n",
        "img = img1.copy()\n",
        "img = cv2.medianBlur(img, 5)\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "\n",
        "# 円の検出\n",
        "circles = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT, 1, 20,\n",
        "                           param1=50, param2=60, minRadius=0, maxRadius=0)\n",
        "\n",
        "# 結果を描画するための画像を準備\n",
        "img_result = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "# 検出した円の描画\n",
        "circles = np.uint16(np.around(circles))\n",
        "for i in circles[0, :]:\n",
        "    # 円を描画\n",
        "    cv2.circle(img_result, (i[0], i[1]), i[2] ,(0, 255, 0), 2)\n",
        "    # 円の中心を描画\n",
        "    cv2.circle(img_result, (i[0], i[1]), 2, (0, 0, 255), 3)\n",
        "\n",
        "plt.imshow(img_result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NgcftZUmoXf",
        "colab_type": "text"
      },
      "source": [
        "## フーリエ変換\n",
        "\n",
        "画像処理におけるフーリエ変換は画像の表現方法を空間領域から周波数領域へ変換する処理である．\n",
        "画像の周波数領域変換は，2次元の離散フーリエ変換（2D-DFT）を適用することで実現される．\n",
        "\n",
        "以下では，離散フーリエ変換を行い，周波数領域表現を抽出する．\n",
        "また，抽出した周波数領域に対してローパスフィルタ，ハイパスフィルタを適用し，画像の変化を確認する．\n",
        "\n",
        "\n",
        "まず，フーリエ変換により周波数領域表現に変換する．\n",
        "フーリエ変換はNumpyの`fft2`関数を用いる．\n",
        "`fft2`関数に変換したいグレースケール画像を入力することで，周波数領域表現 (`img_fft`) を得る．\n",
        "その後，周波数領域表現を表示するために，`img_fft`の直流成分が画像の中心に位置するようにデータを移動する．\n",
        "具体的には，Numpyの`fftshift`関数を利用することで，入れ替えを行う．\n",
        "その後，値の絶対値 (`np.abs`) を取得し，対数変換 (`np.log`) を適用する．\n",
        "対数変換を適用することで，目視による周波数表現の確認を容易にする．\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0kMzxCvHU0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = img3.copy()\n",
        "\n",
        "# 2次元のフーリエ変換\n",
        "img_fft = np.fft.fft2(img)\n",
        "\n",
        "# 直流成分が画像の中心に位置するよう移動\n",
        "img_fft2 = np.fft.fftshift(img_fft)\n",
        "\n",
        "# 表示用に値を変換\n",
        "magnitude_spectrum = np.log(np.abs(img_fft2))\n",
        "\n",
        "# 結果の表示\n",
        "plt.figure(figsize=(8, 12))\n",
        "plt.subplot(211), plt.imshow(img, cmap='gray')\n",
        "plt.title('Input Image')\n",
        "plt.subplot(212), plt.imshow(magnitude_spectrum, cmap='gray')\n",
        "plt.title('Magnitude Spectrum')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuvPjaBlAJi-",
        "colab_type": "text"
      },
      "source": [
        "#### ローパスフィルタ\n",
        "\n",
        "画像には低周波成分が多く含まれており，高周波成分は低周波成分と比べ少ないという特徴がある．\n",
        "そこで，ローパスフィルタでは，画像の低周波成分のみを残し，それ以外の高周波成分を削除するフィルタ処理の一種である．\n",
        "\n",
        "まず，フィルタサイズとして，フィルタを適用する際の中心からの半径を指定する．\n",
        "その後，上のプログラムと同様に，フーリエ変換を適用する．\n",
        "\n",
        "次に，ローパスフィルタを適用するために，フィルタ適用後の値を保存するための配列 (`lowpass`) を用意する．\n",
        "その後，フィルタ内（中心部分）値だけをそのまま`lowpass`へと保存し，フィルタリングを行う．\n",
        "\n",
        "フーリエ変換とは逆の手順で，ローパスフィルタを適用した周波数領域表現のデータを画像へと再構成する．\n",
        "逆フーリエ変換を行うための`ifft2`関数を用いて，周波数成分から画像へ再構成を行う．\n",
        "`ifft2`関数で得られた結果は複素表現となっているため，実部のみを取り出して画像を取得する．\n",
        "\n",
        "ローパスフィルタを適用することで，画像の高周波細かな画素値の変化が失われ，ぼやけた画像が復元されていることがわかる．\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJLPWUrIk3QD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# フィルタサイズ（中心からの半径）を指定\n",
        "r = 40\n",
        "\n",
        "# 画像を用意しフーリエ変換を適用（上のプログラムと同様）\n",
        "img = img3.copy()\n",
        "img_fft = np.fft.fft2(img)\n",
        "# 直流成分が画像の中心に位置するよう移動\n",
        "img_fft2 = np.fft.fftshift(img_fft)\n",
        "\n",
        "# 画像サイズの取得\n",
        "h, w = img_fft.shape\n",
        "# 画像の中心座標の取得\n",
        "cy, cx = int(h/2), int(w/2)\n",
        "\n",
        "# ローパスフィルタ後の値を保存するための配列を用意\n",
        "lowpass = np.zeros(img_fft.shape, dtype=complex)\n",
        "\n",
        "# 中心部分の値だけ代入（中心部分以外は0のまま）\n",
        "for y in range(h):\n",
        "  for x in range(w):\n",
        "    if np.sqrt((x - cx)**2 + (y - cy)**2) < r:\n",
        "      lowpass[y, x] = img_fft2[y, x]\n",
        "\n",
        "# ローパスフィルタを適用した周波数成分の表示\n",
        "plt.imshow(np.log(np.abs(lowpass)), cmap=\"gray\")\n",
        "plt.show()\n",
        "\n",
        "# 画像の再構成\n",
        "lowpass = np.fft.fftshift(lowpass)\n",
        "# 周波数成分からの画像の再構成（逆フーリエ変換）\n",
        "img_lowpass = np.fft.ifft2(lowpass)\n",
        "# 複素数表現の実部のみを取り出す\n",
        "img_lowpass = np.uint8(img_lowpass.real)\n",
        "\n",
        "# 再構成した画像の表示\n",
        "plt.imshow(img_lowpass, cmap=\"gray\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKxcgiK1AKhW",
        "colab_type": "text"
      },
      "source": [
        "#### ハイパスフィルタ\n",
        "\n",
        "ハイパスフィルタはローパスフィルタとは逆に高周波成分のみを残すようなフィルタ処理の一種である．\n",
        "\n",
        "上記のローパスフィルタと同様の手順で行うが，フィルタ処理によって残す情報が異なり，中心以外（円の外側）のみ情報を残す．\n",
        "\n",
        "ハイパスフィルタを適用することで，高周波成分のみが復元されるため，髪の毛の部分などの細かな画素値の変化がある部分の情報のみが残される．\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zXVAAk4AKut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# フィルタサイズ（円の半径）を指定\n",
        "r = 50\n",
        "\n",
        "# 画像を用意しフーリエ変換を適用（上のプログラムと同様）\n",
        "img = img3.copy()\n",
        "img_fft = np.fft.fft2(img)\n",
        "# 直流成分が画像の中心に位置するよう移動\n",
        "img_fft2 = np.fft.fftshift(img_fft)\n",
        "\n",
        "# 画像サイズの取得\n",
        "h, w = img_fft.shape\n",
        "# 画像の中心座標の取得\n",
        "cy, cx = int(h/2), int(w/2)\n",
        "\n",
        "# ローパスフィルタ後の値を保存するための配列を用意\n",
        "highpass = np.zeros(img_fft.shape, dtype=complex)\n",
        "\n",
        "# 中心部分の値だけ代入（中心部分以外は0のまま）\n",
        "for y in range(h):\n",
        "  for x in range(w):\n",
        "    if np.sqrt((x - cx)**2 + (y - cy)**2) > r:\n",
        "      highpass[y, x] = img_fft2[y, x]\n",
        "\n",
        "# ローパスフィルタを適用した周波数成分の表示\n",
        "plt.imshow(np.log(np.abs(highpass)), cmap=\"gray\")\n",
        "plt.show()\n",
        "\n",
        "# 画像の再構成\n",
        "highpass = np.fft.fftshift(highpass)\n",
        "# 周波数成分からの画像の再構成（逆フーリエ変換）\n",
        "img_highpass = np.fft.ifft2(highpass)\n",
        "# 複素数表現の実部のみを取り出す\n",
        "img_highpass = np.uint8(img_highpass.real)\n",
        "\n",
        "# 再構成した画像の表示\n",
        "plt.imshow(img_highpass, cmap=\"gray\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ya22ardAAK16",
        "colab_type": "text"
      },
      "source": [
        "## 課題\n",
        "\n",
        "\n",
        "* ハフ変換に使用される関数`cv2.HoughLinesP`,`cv2.HoughCircles`の引数を変更し，変化を確認すること\n",
        "* ローパスフィルタ，ハイパスフィルタのフィルタサイズ`r`を変更し，変化を確認すること"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Zyc2_EaAK8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}