{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/machine-perception-robotics-group/ImageProcessingGoogleColabNotebooks/blob/master/07_keypoint_detection_description.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3PEKFt0aBbLw"
      },
      "source": [
        "# 07. キーポイントマッチング\n",
        "\n",
        "講義で説明する画像処理の方法について，google colaboratoryを利用して演習する．\n",
        "google colaboratoryは，クラウドで実行する Jupyter ノートブック環境である.\n",
        "google coraboratoryについては，[ここ](https://www.tdi.co.jp/miso/google-colaboratory-gpu)や[ここ](https://www.codexa.net/how-to-use-google-colaboratory/)を参考にすること．\n",
        "\n",
        "下記のプログラムを実行すると，SIFT特徴量のキーポイント検出と特徴量記述，キーポイントマッチングを実行する．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rWiFoTeTBkyd"
      },
      "source": [
        "## 準備\n",
        "\n",
        "SIFTを使用するために，下記のコマンドを実行してOpenCVのバージョンを指定して再インストールする．\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Dd5WZeZS_NNJ"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python==4.10.0.84\n",
        "!pip install opencv-contrib-python==4.10.0.84"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6HAJV7kV_NJI"
      },
      "source": [
        "**注意:** 以下のプログラムでエラーが発生した場合は，上記のOpenCVの再インストールコマンドを実行した後，ページ上部のメニューバーから「ランタイム --> ランタイムを再起動」を選択し，実行し直してください．\n",
        "\n",
        "\n",
        "\n",
        "プログラムの動作に必要なデータをダウンロードし，zipファイルを解凍する．\n",
        "`!`で始まるコマンドはPythonではなく，Linux（Ubuntu）のコマンドを実行している．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3NYtuZtndzQ4"
      },
      "outputs": [],
      "source": [
        "!wget -q https://raw.githubusercontent.com/machine-perception-robotics-group/ImageProcessingGoogleColabNotebooks/master/image1.zip\n",
        "!unzip -q image1.zip\n",
        "!ls\n",
        "!ls ./image1/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OC8WORLyBql_"
      },
      "source": [
        "## 画像の読み込みと表示\n",
        "必要なパッケージをインポートし，画像を表示する．\n",
        "\n",
        "`img2`はキーポイントマッチングのために，45度回転させる．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YFl5XkzmZCg9"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "img1 = cv2.imread('./image1/woman-g.jpg', 0)\n",
        "img2 = cv2.imread('./image1/woman-t.jpg', 0)\n",
        "\n",
        "# 画像を45度回転\n",
        "h, w = img2.shape\n",
        "trans = cv2.getRotationMatrix2D((int(h/2), int(w/2)), 45 , 1.0)\n",
        "img2 = cv2.warpAffine(img2, trans, (h, w))\n",
        "\n",
        "plt.imshow(img1, cmap=\"gray\", clim=(0, 255))\n",
        "plt.show()\n",
        "plt.imshow(img2, cmap=\"gray\", clim=(0, 255))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RERTDsdkJIEU"
      },
      "source": [
        "## SIFT\n",
        "\n",
        "SIFTの処理は\n",
        "1. キーポイント検出\n",
        "2. 特徴記述\n",
        "\n",
        "の2ステップから構成されている．\n",
        "\n",
        "以下では，それぞれのステップの処理を実行し，その結果を確認する．\n",
        "SIFTのキーポイント検出，特徴記述の処理は複雑なため，今回はOpenCVに含まれている関数を利用して行う．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "24KNxhM4BhdU"
      },
      "source": [
        "### キーポイントの検出\n",
        "\n",
        "まずはじめに，OpenCVの`SIFT_create`を呼び出す．\n",
        "`SIFT_create`の呼び出しでは，まだキーポイント検出や特徴記述等は行なっておらず，SIFTの計算を行う際のパラメータ等を指定し，SIFTの計算を行うためのオブジェクト（クラスインスタンス）を作成している．\n",
        "その後．`detect`関数にキーポイント検出をしたい画像を入力し，検出したキーポイント（`keypoints`）を返す．\n",
        "\n",
        "`keypoints`を表示すると，\n",
        "\n",
        "> [<KeyPoint 0x7f5157ce1630>, <KeyPoint 0x7f5157ce1540>, <KeyPoint 0x7f5157ce1690>, ... ]\n",
        "\n",
        "のような文字が表示される．\n",
        "これは，`detect`関数で検出されたキーポイントが，OpenCVの`KeyPoint`オブジェクトとしてリスト内に保存されいている．\n",
        "一つ一つの`KeyPoint`オブジェクトには\n",
        "* `pt`：キーポイントの座標\n",
        "* `size`：キーポイントのスケール\n",
        "* `angle`：キーポイントのオリエンテーション\n",
        "\n",
        "などのような値が存在している．\n",
        "（より詳細な情報を知りたい人は[OpenCVのドキュメント](https://docs.opencv.org/3.4/d2/d29/classcv_1_1KeyPoint.html)を参照すること）\n",
        "\n",
        "ここで，`keypoints`のうち，0番目と1番目の`KeyPoint`の中身を表示すると，各キーポイントの座標やスケール等が数値として格納されていることがわかる．\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "g5jET4_enP6S"
      },
      "outputs": [],
      "source": [
        "img = img1.copy()\n",
        "\n",
        "# 画像を正規化\n",
        "img = cv2.normalize(img, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
        "\n",
        "# SIFTを計算するための準備\n",
        "sift = cv2.SIFT_create(nfeatures=0, nOctaveLayers=3, contrastThreshold=0.04, edgeThreshold=10, sigma=1.6)\n",
        "# SIFTの検出\n",
        "keypoints = sift.detect(img)\n",
        "\n",
        "print(keypoints[:10])\n",
        "print(keypoints[0].pt, keypoints[0].size, keypoints[0].angle)\n",
        "print(keypoints[1].pt, keypoints[1].size, keypoints[1].angle)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HbF_G98hhV80"
      },
      "source": [
        "上で検出したキーポイントを画像へ描画する．\n",
        "\n",
        "はじめに，描画用の画像を用意する．\n",
        "この時，検出結果をカラーで表示するために，グレースケール画像からRGB画像へ変換しておく．\n",
        "\n",
        "\n",
        "キーポイントの座標点の描画を行う．\n",
        "for文でリスト内のキーポイントを一つづつ取り出し，座標点 (`pt`) の値に従い，点を描画する．\n",
        "描画には画像中に円を描く`circle`関数を用いる．\n",
        "\n",
        "次に，スケールを描画する．\n",
        "スケールの描画には座標点と同様`circle`関数を使用する．\n",
        "この時．円の半径を指定する第3引数をキーポイントのスケール (`size`) で指定することで，スケールを円の大きさで表示する．\n",
        "\n",
        "最後に，オリエンテーションを描画する．\n",
        "オリエンテーションの描画には，直線を描画する`line`関数を使用する．\n",
        "この時，座標点からオリエンテーションの方向に従ってスケールの円に接するまでの直線を描画するが，`line`関数は直線の両端点を座標で指定する必要があるため．オリエンテーションから端点を算出する．\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_oJmFEf9hWDg"
      },
      "outputs": [],
      "source": [
        "# 描画用の画像を用意\n",
        "img_sift1 = img1.copy()\n",
        "# 検出結果をカラーで表示するため，グレースケールからRGB画像へ変換\n",
        "img_sift1 = cv2.cvtColor(img_sift1, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "# 座標点の描画\n",
        "for k in keypoints:\n",
        "  img_sift1 = cv2.circle(img_sift1, (int(k.pt[0]), int(k.pt[1])), 1, (0, 255, 0), -1)\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(img_sift1)\n",
        "plt.show()\n",
        "\n",
        "# スケールの描画\n",
        "for k in keypoints:\n",
        "  img_sift1 = cv2.circle(img_sift1, (int(k.pt[0]), int(k.pt[1])), int(k.size), (0, 255, 0), 1)\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(img_sift1)\n",
        "plt.show()\n",
        "\n",
        "# オリエンテーションの描画\n",
        "for k in keypoints:\n",
        "  ori_x = int(k.pt[0] + math.cos(math.radians(k.angle)) * k.size)\n",
        "  ori_y = int(k.pt[1] + math.sin(math.radians(k.angle)) * k.size)\n",
        "  img_sift1 = cv2.line(img_sift1, (int(k.pt[0]), int(k.pt[1])), (ori_x, ori_y), (0, 255, 0), 1)\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(img_sift1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2U0apWcQKWwc"
      },
      "source": [
        "OpenCVの`drawKeypoints`関数を用いることでも，上と同様のキーポイントの描画を行うことができる．\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "y8r7zeSVKW4L"
      },
      "outputs": [],
      "source": [
        "img_sift2 = cv2.drawKeypoints(img, keypoints, None, flags=4)\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(img_sift2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KBubh3niJvh4"
      },
      "source": [
        "### 特徴量の記述\n",
        "\n",
        "次に，検出したキーポイントに対する，特徴量の記述を行う．\n",
        "特徴量の記述にも，`SIFT_create`で作成したオブジェクトを使用する．\n",
        "ここでは，上のプログラムで作成したオブジェクト`sift`を利用する．\n",
        "`compute`関数に，画像と記述したい特徴量のキーポイントを入力することで，キーポイント`keypoints`と特徴量`desc`を返す．\n",
        "ここで，`keypoints`は上で計算したものと同様である．\n",
        "\n",
        "記述した特徴量を表示してみる．\n",
        "`desc`は入れ子になったリストである．\n",
        "1次元目が検出（記述）したキーポイントの数に対応しており．2次元目が各キーポイントの特徴量である．\n",
        "SIFT特徴量は128次元であるため，2次元目の配列の長さも128となっている．\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5uOyQBZOCEqj"
      },
      "outputs": [],
      "source": [
        "# SIFT特徴量の記述\n",
        "keypoints, desc = sift.compute(img, keypoints)\n",
        "\n",
        "# 記述された特徴量（配列）のサイズの確認\n",
        "print(desc)\n",
        "print(\"the number of descriptors:\", len(desc))\n",
        "\n",
        "# 記述された特徴量の表示\n",
        "print(desc[0])\n",
        "print(\"length of each SIFT descriptor:\", len(desc[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LEI23B76JxbV"
      },
      "source": [
        "## SIFTによるキーポイントマッチング\n",
        "\n",
        "次に，SIFT特徴量を用いて，キーポイントのマッチングを行う．\n",
        "ここでは，ページ上部で読み込んだ2枚の画像間でマッチングを行う．\n",
        "\n",
        "まず，それぞれの画像からキーポイントを検出し，キーポイントに対応する特徴量を記述する．\n",
        "ここでは，`detectAndCompute`という関数を使用しており，前述のキーポイント検出`detect`と特徴量記述`compute`を一度に行う関数となっている．\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "uLw2UQ9gDBR8"
      },
      "outputs": [],
      "source": [
        "img = img1.copy()\n",
        "img_query = img2.copy()\n",
        "\n",
        "# 画像を正規化\n",
        "img = cv2.normalize(img, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
        "img_query = cv2.normalize(img_query, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
        "\n",
        "# SIFT特徴量の検出と記述\n",
        "sift = cv2.SIFT_create(nfeatures=0, nOctaveLayers=3, contrastThreshold=0.04, edgeThreshold=10, sigma=1.6)\n",
        "kp, desc = sift.detectAndCompute(img, None)\n",
        "kp_q, desc_q = sift.detectAndCompute(img_query, None)\n",
        "print(\"the number of keypoints (original image):\", len(kp))\n",
        "print(\"the number of keypoints (query image):\", len(kp_q))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9KpnBIRmlvgI"
      },
      "source": [
        "次に，記述した特徴量間で距離を計算し，対応点を探索する．\n",
        "\n",
        "距離の計算には，ユークリッド距離を使用するため，2つの特徴量間のユークリッド距離を計算するための関数`euclidean_dist`を定義する．\n",
        "この関数では，2つの特徴量（`x1`, `x2`）を引数として入力し，そのユークリッド距離を返すものである．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "M7HbdeBwS6Yl"
      },
      "outputs": [],
      "source": [
        "def euclidean_dist(x1, x2):\n",
        "  if len(x1) != len(x2):\n",
        "    print(\"ERROR: input data lengths are different.\")\n",
        "    exit(-1)\n",
        "  x1 = np.array(x1, dtype=np.float32)\n",
        "  x2 = np.array(x2, dtype=np.float32)\n",
        "  dist = np.sqrt(np.sum(np.power(x1 - x2, 2)))\n",
        "  return dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r4ghhVggmXsl"
      },
      "source": [
        "上で定義した`euclidean_dist`関数を利用して，対応点の探索を行う．\n",
        "\n",
        "\n",
        "まず，マッチングしたキーポイントの情報を格納するためのリスト`matched_keypoints`を用意する．\n",
        "\n",
        "その後，一つ目の画像から記述された特徴量`desc`と二つ目の画像の特徴量`desc_q`をfor文で一つづつ取り出しながら，対応点探索を行う．\n",
        "\n",
        "この時，取り出した特徴量に対応する番号（インデックス）を同時に扱うために，`enumerate`関数を利用する．\n",
        "`enumerate`関数を用いてfor文を実行した場合，通常のfor文で取り出す変数とは別に`0, 1, 2, ...`というインデックスを同時に受け取ることが可能である．\n",
        "\n",
        "まず，1枚目の画像のとある特徴量`d1`に対して，2枚目の画像の特徴量全てとのユークリッド距離を計算し，その値を`distances`に一時格納する．\n",
        "\n",
        "その後，`distances`に格納されたユークリッド距離のうち，最も距離が小さい2つの特徴量の番号を`near_1st`, `near_2nd`に保存する．\n",
        "この2つの特徴量に$d_{1}<d_{2} \\times 0.6$の関係が成立する場合，1番目の特徴量は`d1`と対応しているとみなして．`matched_keypoints`にその特徴量のインデックスを保存する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FuPJmoRFTr0i"
      },
      "outputs": [],
      "source": [
        "matched_keypoints = []\n",
        "for i, d1 in enumerate(desc):\n",
        "  distances = []\n",
        "  for j, d2 in enumerate(desc_q):\n",
        "    distances.append(euclidean_dist(d1, d2))\n",
        "  \n",
        "  # 計算した距離を昇順に並べ替え\n",
        "  near_order = np.argsort(distances)\n",
        "  # 距離が1番目と2番目に小さいものを取得\n",
        "  near_1st = distances[near_order[0]]\n",
        "  near_2nd = distances[near_order[1]]\n",
        "\n",
        "  if near_1st < (near_2nd * 0.6):\n",
        "    matched_keypoints.append((i, near_order[0]))\n",
        "\n",
        "print(\"the number of matched keypoints:\", len(matched_keypoints))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nCz_G1o5WA74"
      },
      "source": [
        "### 対応点の描画\n",
        "\n",
        "対応点の探索が終了したら，対応点の描画を行う．\n",
        "\n",
        "対応点を線で結んで表示するために，1枚の画像に2つの画像を表示する．\n",
        "\n",
        "対応点の描画を行うために，`matched_keypoints`に格納されたインデックスのペアをfor文で一つづつ取り出して描画を行う．\n",
        "各インデックスに対応するキーポイントの座標（`pt`）をリストから抽出し，`point1`, `point2`に格納する．\n",
        "この時，`point2`は画像の右側に位置するように，x軸の値に1枚目の画像の横幅を加える．\n",
        "その後．`point1`, `point2`それぞれの座標に点（円）を`circle`で描画し，`line`関数で直線を引くことで，対応点を描画する．\n",
        "各対応点をわかりやすくするために，対応点ごとにランダムでRGB値を決定し，描画している．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XJ4VF99HV6TX"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "h1, w1 = img.shape\n",
        "h2, w2 = img_query.shape\n",
        "# 2枚の画像を1つに表示するように配列を作成\n",
        "img_match = np.zeros([h1, w1 + w2], dtype=np.uint8)\n",
        "# 左側に1枚目をコピー\n",
        "img_match[0:h1, 0:w1] = img.copy()\n",
        "# 右側に2枚目をコピー\n",
        "img_match[0:h2, w1:w1+w2] = img_query.copy()\n",
        "# 検出結果をカラーで表示するため，グレースケールからRGB画像へ変換\n",
        "img_match = cv2.cvtColor(img_match, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "# 対応点の描画\n",
        "for p1, p2 in matched_keypoints:\n",
        "  point1 = (int(kp[p1].pt[0]), int(kp[p1].pt[1]))\n",
        "  point2 = (int(w1 + kp_q[p2].pt[0]), int(kp_q[p2].pt[1]))\n",
        "  color = (random.randint(30, 255), random.randint(30, 255), random.randint(30, 255))\n",
        "  img_match = cv2.circle(img_match, point1, 3, color, 1)\n",
        "  img_match = cv2.circle(img_match, point2, 3, color, 1)\n",
        "  img_match = cv2.line(img_match, point1, point2, color, 1)\n",
        "\n",
        "# 表示\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(img_match)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W4bCYbHIb3hk"
      },
      "source": [
        "OpenCVの`knnMatch`関数と`drawMatchesKnn`関数を用いることでも同様の処理が可能である．\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rKsd-vECZK0D"
      },
      "outputs": [],
      "source": [
        "bf = cv2.BFMatcher()\n",
        "matches = bf.knnMatch(desc, desc_q, k=2)\n",
        "\n",
        "# Apply ratio test\n",
        "good = []\n",
        "for m, n in matches:\n",
        "    if m.distance < 0.6 * n.distance:\n",
        "        good.append([m])\n",
        "\n",
        "# cv2.drawMatchesKnn expects list of lists as matches.\n",
        "draw_params = dict(matchColor = (0,255,0),\n",
        "                   singlePointColor = (255,0,0),\n",
        "                   flags = 0)\n",
        "img3 = cv2.drawMatchesKnn(img, kp, img_query ,kp_q, good, None, flags=2)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(img3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Qsn2MGWiJ2wL"
      },
      "source": [
        "## 課題\n",
        "\n",
        "* `SIFT_create`のパラメータを変更した場合に検出されるキーポイントがどのように変化するか確認すること\n",
        "* どのような場所がキーポイントになっているか，考察すること\n",
        "* どのような場所でキーポイントマッチングが成功または失敗しているか，考察すること\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "yAZ-5FOMT5lR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "07_keypoint_detection_description",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
